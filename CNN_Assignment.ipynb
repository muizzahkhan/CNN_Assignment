{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4HrzSspFvqq"
      },
      "source": [
        "# **Downloading Data from Kaggle**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "0CzO8pf1BQAJ",
        "outputId": "9ad907bf-2a35-4a67-9ef8-ce0794e186dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting kaggle\n",
            "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 3.0 MB/s \n",
            "\u001b[?25hCollecting six>=1.10\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting certifi\n",
            "  Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
            "\u001b[K     |████████████████████████████████| 155 kB 9.2 MB/s \n",
            "\u001b[?25hCollecting python-dateutil\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[K     |████████████████████████████████| 247 kB 49.4 MB/s \n",
            "\u001b[?25hCollecting requests\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.3 MB/s \n",
            "\u001b[?25hCollecting tqdm\n",
            "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 6.1 MB/s \n",
            "\u001b[?25hCollecting python-slugify\n",
            "  Downloading python_slugify-7.0.0-py2.py3-none-any.whl (9.4 kB)\n",
            "Collecting urllib3\n",
            "  Downloading urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 62.8 MB/s \n",
            "\u001b[?25hCollecting text-unidecode>=1.3\n",
            "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 6.3 MB/s \n",
            "\u001b[?25hCollecting charset-normalizer<3,>=2\n",
            "  Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
            "Collecting idna<4,>=2.5\n",
            "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 91 kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73052 sha256=c7b871842bee57d3ffc46ed0f5fa016a8249b626cc80e7a76140ece5494a7884\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/da/11/144cc25aebdaeb4931b231e25fd34b394e6a5725cbb2f50106\n",
            "Successfully built kaggle\n",
            "Installing collected packages: urllib3, text-unidecode, six, idna, charset-normalizer, certifi, tqdm, requests, python-slugify, python-dateutil, kaggle\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\u001b[0m\n",
            "Successfully installed certifi-2022.12.7 charset-normalizer-2.1.1 idna-3.4 kaggle-1.5.12 python-dateutil-2.8.2 python-slugify-7.0.0 requests-2.28.1 six-1.16.0 text-unidecode-1.3 tqdm-4.64.1 urllib3-1.26.13\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "dateutil",
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install --upgrade --ignore-installed kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "EBTgVMzgBz2M",
        "outputId": "cec4bf85-c315-470c-bf78-47c3bb8f8a01"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cf2ddb23-8228-4276-9782-bacfb04bfb43\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cf2ddb23-8228-4276-9782-bacfb04bfb43\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"muizzahkhan\",\"key\":\"54bf8e6e9112d814244c3948f03aae43\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyxRBwhXDL1P"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle #created at root folder in colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sNWXPeWDVHG"
      },
      "outputs": [],
      "source": [
        "!cp kaggle.json ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qG6Gmig8DaXr"
      },
      "outputs": [],
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTL2Z07GDi_f",
        "outputId": "8db72a2a-e586-4ad0-9e2c-9ba131ac9772"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ref                                                             title                                             size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "--------------------------------------------------------------  -----------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
            "meirnizri/covid19-dataset                                       COVID-19 Dataset                                   5MB  2022-11-13 15:47:17          10347        307  1.0              \n",
            "michals22/coffee-dataset                                        Coffee dataset                                    24KB  2022-12-15 20:02:12           1532         47  1.0              \n",
            "thedevastator/jobs-dataset-from-glassdoor                       Salary Prediction                                  3MB  2022-11-16 13:52:31           6509        146  1.0              \n",
            "thedevastator/unlock-profits-with-e-commerce-sales-data         E-Commerce Sales Dataset                           6MB  2022-12-03 09:27:17           1054         29  0.9411765        \n",
            "ahmettalhabektas/argentina-car-prices                           Argentina car prices                               8KB  2022-12-05 09:05:21            574         28  1.0              \n",
            "mvieira101/global-cost-of-living                                Global Cost of Living                              1MB  2022-12-03 16:37:53           2738         59  0.9705882        \n",
            "thedevastator/uncovering-wage-disparities-in-pennsylvania-s-hi  Higher Education Wages                           223KB  2022-12-04 15:42:36            913         33  1.0              \n",
            "danela/fatal-alligator-attacks-us                               Fatal Alligator Attacks US                         5KB  2022-12-15 16:37:57            273         24  1.0              \n",
            "kabhishm/best-selling-music-artists-of-all-time                 Best Selling Music Artists of All Time             3KB  2022-12-09 07:04:29            812         37  0.9411765        \n",
            "swaptr/fifa-world-cup-2022-statistics                           FIFA World Cup 2022 Team Data                     15KB  2022-12-19 00:29:15           2126         52  0.9705882        \n",
            "whenamancodes/predict-diabities                                 Predict Diabetes                                   9KB  2022-11-09 12:18:49           6850        115  1.0              \n",
            "die9origephit/fifa-world-cup-2022-complete-dataset              Fifa World Cup 2022: Complete Dataset              7KB  2022-12-18 22:51:11           1517         69  0.9411765        \n",
            "mattop/alcohol-consumption-per-capita-2016                      Alcohol Consumption Per Capita 2016                4KB  2022-12-09 00:03:11           1104         43  1.0              \n",
            "swaptr/fifa-world-cup-2022-match-data                           FIFA World Cup 2022 Match Data                     7KB  2022-12-19 00:30:28           1078         30  1.0              \n",
            "laibaanwer/superstore-sales-dataset                             SuperStore Sales Dataset                           2MB  2022-12-07 08:53:32           1050         29  1.0              \n",
            "thedevastator/discovering-hidden-trends-in-global-video-games   Discovering Hidden Trends in Global Video Games   56KB  2022-12-03 11:21:47            601         36  1.0              \n",
            "prosperchuks/health-dataset                                     Diabetes, Hypertension and Stroke Prediction     750KB  2022-12-13 13:15:19           3036         68  1.0              \n",
            "thedevastator/the-ultimate-netflix-tv-shows-and-movies-dataset  Netflix TV Shows and Movies (2022 Updated)         2MB  2022-11-27 20:41:41           1762         35  0.9705882        \n",
            "catherinerasgaitis/mxmh-survey-results                          Music & Mental Health Survey Results              22KB  2022-11-21 10:03:12           2635         57  1.0              \n",
            "kabhishm/imdb-100-movie-titles                                  IMDB 100 Movies                                    9KB  2022-12-07 11:36:06            443         23  0.9411765        \n"
          ]
        }
      ],
      "source": [
        "! kaggle datasets list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NogN7I67Dmit",
        "outputId": "40fe3ca3-73dc-4dfd-bfbe-235a6b2a6629"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading intel-image-classification.zip to /content\n",
            " 94% 327M/346M [00:02<00:00, 148MB/s]\n",
            "100% 346M/346M [00:02<00:00, 151MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d puneet6060/intel-image-classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONtf_yhYED6v"
      },
      "outputs": [],
      "source": [
        "!unzip -q intel-image-classification.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8X3zt7TEbTj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac211ff8-c5f6-462f-9a73-3df70ad45f7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QCAiMlbEqoX"
      },
      "outputs": [],
      "source": [
        "!cp \"/content/intel-image-classification.zip\" /content/drive/MyDrive/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9HzibrlFszN"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwuQegCHDFPL"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Dense, MaxPooling2D, Flatten\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMQ-0e-YDLmw"
      },
      "outputs": [],
      "source": [
        "# alexnet = Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alexnet = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(128,128,3)),\n",
        "    keras.layers.Conv2D(16, (3,3), activation='relu'),\n",
        "    keras.layers.Conv2D(16, (3,3), activation='relu'),\n",
        "    keras.layers.MaxPool2D(2,2),  #1st layer\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    keras.layers.MaxPool2D(2,2),  #2nd layer\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    keras.layers.MaxPool2D(2,2),  #3rd layer\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    keras.layers.MaxPool2D(2,2),  #4th layer\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(6, activation='softmax')                                                       \n",
        "])"
      ],
      "metadata": {
        "id": "nzK2L-BX9pMK"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# alexnet.add(Conv2D(96, (11, 11), strides=(4,4), padding='same', activation='relu', input_shape=(32, 32, 3)))\n",
        "# alexnet.add(MaxPooling2D((3,3), strides=(2,2), padding='same'))\n",
        "\n",
        "# alexnet.add(Conv2D(256, (5,5), padding='same', activation='relu'))\n",
        "# alexnet.add(MaxPooling2D((3,3), strides=(2,2), padding='same'))\n",
        "\n",
        "# alexnet.add(Conv2D(384, (3,3), padding='same', activation='relu'))\n",
        "# alexnet.add(Conv2D(384, (3,3), padding='same', activation='relu'))\n",
        "# alexnet.add(Conv2D(384, (3,3), padding='same', activation='relu'))\n",
        "# alexnet.add(MaxPooling2D((3,3), strides=(2,2), padding='same'))\n",
        "\n",
        "# # flatten the input feature map. here it flattens the last feature map before it\n",
        "# alexnet.add(Flatten())\n",
        "\n",
        "# # add FC layers. Using less no. of neurons here\n",
        "# alexnet.add(Dense(384, activation='relu'))\n",
        "# alexnet.add(Dense(384, activation='relu'))\n",
        "\n",
        "# # add FC layer with 10 units for we have 10 classes\n",
        "# # use softmax activation for classification\n",
        "# alexnet.add(Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "sI7Z7A6btyKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alexnet.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UFmipNbt2Z1",
        "outputId": "4bea475c-f252-4d68-e474-417bcaaff8e1"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_5 (Conv2D)           (None, 126, 126, 16)      448       \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 124, 124, 16)      2320      \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 122, 122, 16)      2320      \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 61, 61, 16)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 61, 61, 16)        0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 59, 59, 32)        4640      \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 57, 57, 32)        9248      \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 55, 55, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 27, 27, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 27, 27, 32)        0         \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 25, 25, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 23, 23, 64)        36928     \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 21, 21, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 10, 10, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 10, 10, 64)        0         \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 6, 6, 128)         147584    \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 4, 4, 128)         147584    \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 2, 2, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 128)               65664     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 6)                 774       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 556,038\n",
            "Trainable params: 556,038\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = \"/content/seg_train/seg_train\"\n",
        "test_path = \"/content/seg_test/seg_test\"\n"
      ],
      "metadata": {
        "id": "YX1GbZ1vt4U9"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "Kd8PDou_uIxd"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "training_set = train_datagen.flow_from_directory(train_path, target_size=(128,128), batch_size=32, class_mode = 'categorical')\n",
        "testing_set = test_datagen.flow_from_directory(test_path, target_size=(128,128), batch_size=32, class_mode = 'categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yl797Lu0Q1f",
        "outputId": "ea12a4cc-2924-4475-951c-ffebabf6d466"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 14034 images belonging to 6 classes.\n",
            "Found 3000 images belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam\n",
        "alexnet.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "     "
      ],
      "metadata": {
        "id": "AuVM5E5k46AY"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "import h5py\n"
      ],
      "metadata": {
        "id": "-R4uOGIn5COo"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "erl_stop = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n",
        "mod_chk = ModelCheckpoint(filepath='/kaggle/working/my_model.hdf5', monitor='val_loss', save_best_only=True)\n",
        "lr_rate = ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.1)"
      ],
      "metadata": {
        "id": "wVfrYhbD6MCB"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = alexnet.fit(training_set, shuffle=True, epochs=20, validation_data=testing_set,\n",
        "                           callbacks=[erl_stop, mod_chk, lr_rate], verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QWvNjhq7dsd",
        "outputId": "25c05ef9-31ae-4c58-9859-ce8effc868be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "439/439 [==============================] - 986s 2s/step - loss: 1.3207 - accuracy: 0.4462 - val_loss: 1.0673 - val_accuracy: 0.5210 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "362/439 [=======================>......] - ETA: 2:43 - loss: 1.0547 - accuracy: 0.5718"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jtZob7t87gag"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}